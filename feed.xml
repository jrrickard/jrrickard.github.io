<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>code to run, run to live</title>
    <description>A blog about running, software and beverages. Opinions expressed are my own
</description>
    <link>http://jrrickard.github.io/</link>
    <atom:link href="http://jrrickard.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 16 Oct 2016 20:15:03 -0600</pubDate>
    <lastBuildDate>Sun, 16 Oct 2016 20:15:03 -0600</lastBuildDate>
    <generator>Jekyll v2.4.0</generator>
    
      <item>
        <title>Comparing Spring and Xenon</title>
        <description>&lt;p&gt;In my last job, our Java development exclusively used the &lt;a href=&quot;https://spring.io/&quot;&gt;Spring&lt;/a&gt; ecosystem. In my current job, we&amp;#39;re instead using &lt;a href=&quot;https://vmware.github.io/xenon/&quot;&gt;Project&lt;/a&gt; &lt;a href=&quot;https://github.com/vmware/xenon&quot;&gt;Xenon&lt;/a&gt;. Both frameworks enable you to build services, but help you get there with pretty different approaches. To provide some comparison between the two, I&amp;#39;ve gone ahead and built the same application twice: one using Spring and one using Xenon.&lt;/p&gt;

&lt;p&gt;The Spring based application is written using Spring Boot, Spring MVC, Spring Data and a Mongo DB instance. I need to add everything to github still, but when I do there will be a some scripts to build the source, package as Docker and a Docker compose file that will run the app. The Xenon app, on the otherhand, is written only using the Xenon framework. Xenon makes use of Lucene as a persistence layer, so it does not need an external database. &lt;/p&gt;

&lt;p&gt;Stay tuned for three blog posts this week: &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;First, I will walk through the Spring app&lt;/li&gt;
&lt;li&gt;Next, I will walk through the Xenon app&lt;/li&gt;
&lt;li&gt;I&amp;#39;ll offer my thoughts comparing the two.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 20:07:21 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/10/16/comparing-spring-and-xenon.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/10/16/comparing-spring-and-xenon.html</guid>
        
        
      </item>
    
      <item>
        <title>Marathon-LB and Zero Downtime Deployments</title>
        <description>&lt;p&gt;We&amp;#39;re currently using Marathon-lb to act as a sort of service discovery for our application and the services we are deploying. With our application, we need to deploy a new cluster for our application and initiate a data migration when we need to update. This poses a problem with our current use of Google&amp;#39;s Load Balancer and Marathon-lb, namely the use of service ports. After trying a few things, we settled on creating another load balancer pointing at a new service port and swapping our DNS records. That&amp;#39;s somewhat time consuming though and extra for us to automate for upgrades. After reading the &lt;a href=&quot;https://github.com/mesosphere/marathon-lb/blob/master/README.md#zero-downtime-deployments&quot;&gt;Zero Downtime Deployments&lt;/a&gt; section of the Marathon-lb documentation, it sounded like a decent fit for what we needed. Not a 100% fit given our deploy-&amp;gt;migrate upgrade sequence, which can take 15+ minutes to complete, but close. I decided to try to get the Marathon-lb portion of this working using the HAPROXY_ labels described in the documentation.&lt;/p&gt;

&lt;p&gt;This failed with lots of Python errors, and I believe it is due to the older version of Marathon-lb we are running. We haven&amp;#39;t fully migrated our production environments to DC/OS yet, and we&amp;#39;re running a version of Marathon-lb that is quite old in the scope of Marathon&amp;#39;s life. I decided to try this out with my DC/OS lab and spun up the latest Marathon-lb instance. I decided to run this outside of Marathon because I was experimenting with a number of config options and it was easier to just run via the command line....and I only have one agent currently so that&amp;#39;s not a big deal. I&amp;#39;ve settled on the config I want, so I can migrate it back into Marathon now. &lt;/p&gt;

&lt;p&gt;Following the steps described MOSTLY worked. I simply changed our JSON definition to include:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;HAPROXY_DEPLOYMENT_GROUP=csp
HAPROXY_DEPLOYMENT_ALT_PORT=10101
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running that, I saw it pick up both applications after I deployed the new containers:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;marathon_lb: fetching apps
marathon_lb: GET http://master.mesos:8080/v2/apps?embed=apps.tasks
marathon_lb: got apps [&amp;#39;/csp-host&amp;#39;, &amp;#39;/csp-host-2&amp;#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, it immediately started spewing Python errors:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;marathon_lb: Unexpected error!
Traceback (most recent call last):
  File &amp;quot;/marathon-lb/marathon_lb.py&amp;quot;, line 1357, in do_reset
    self.__apps = get_apps(self.__marathon)
  File &amp;quot;/marathon-lb/marathon_lb.py&amp;quot;, line 1178, in get_apps
    int(new[&amp;#39;labels&amp;#39;][&amp;#39;HAPROXY_DEPLOYMENT_TARGET_INSTANCES&amp;#39;])
KeyError: &amp;#39;HAPROXY_DEPLOYMENT_TARGET_INSTANCES&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The documentation suggested that wasn&amp;#39;t something you should NEED to set, but it showed up nonetheless. I&amp;#39;m guessing that because I was not using the Zero Downtime Deployment scripts, I needed to provide this. This was pretty easy to fix, I just needed to add that label to the JSON config.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;HAPROXY_DEPLOYMENT_GROUP=csp
HAPROXY_DEPLOYMENT_TARGET_INSTANCES=3
HAPROXY_DEPLOYMENT_ALT_PORT=10101
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After adding that and waiting for the app to restart, I was able to access both of my application clusters via the same service port.&lt;/p&gt;

&lt;p&gt;Since we can&amp;#39;t really use the ZDD script, I made my own Python script that handles our use case....namely:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Fetch a task from the old cluster&lt;/li&gt;
&lt;li&gt;Get the IP and Port combo&lt;/li&gt;
&lt;li&gt;Grab a task from the new cluster&lt;/li&gt;
&lt;li&gt;Get the IP and Port combo&lt;/li&gt;
&lt;li&gt;Build an upgrade request to the new task using the old task as the source node&lt;/li&gt;
&lt;li&gt;Wait for the upgrade request to finish&lt;/li&gt;
&lt;li&gt;Modify the new cluster to add the tags above.&lt;/li&gt;
&lt;li&gt;Trigger a tag of the image in Bintray to represent our currently deployed state&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The last step was really the important part to keep the new cluster from receiving traffic before the upgrade is complete. Once the upgrade is complete and we&amp;#39;ve verified the new instance, the old one can be removed from Marathon. &lt;/p&gt;
</description>
        <pubDate>Wed, 10 Aug 2016 15:51:48 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/08/10/marathon-lb-and-zero-downtime-deployments.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/08/10/marathon-lb-and-zero-downtime-deployments.html</guid>
        
        
      </item>
    
      <item>
        <title>Installing CentOS and DC/OS</title>
        <description>&lt;p&gt;With all my hardware setup, I need to install an OS and then setup DC/OS. The DC/OS installation scripts are somewhat limited in what they will operate with out of the box, primarily CentOS and CoreOS. CentOS is a little more in line with what I need right now, so I&amp;#39;ve decided to do that. &lt;/p&gt;

&lt;h1&gt;Installing CentOS&lt;/h1&gt;

&lt;p&gt;I chose to do a minimal installation of CentOS and add from there. I went back and forth on installing via PXE or USB and decided to go with the USB installation because I already had the CentOS ISO written to a USB stick. &lt;/p&gt;

&lt;p&gt;After getting everything up and running, I did go back and configure my Synology to act as a PXE boot server and that has worked out pretty well. I&amp;#39;ll do another post on that later. &lt;/p&gt;

&lt;h2&gt;Setup SSH Keys&lt;/h2&gt;

&lt;p&gt;Once I had everything setup, I went ahead and added my SSH keys to the server. This turned out to be a good thing to do, as the DC/OS installation makes use of SSH keys to remotely connect to the nodes you&amp;#39;ll be configuring, so go ahead and do that now for the user you plan on installing DC/OS with. I used ssh-copy-id, which isn&amp;#39;t installed by default on MacOS X, but is super easy to install with &lt;a href=&quot;http://brew.sh/&quot;&gt;homebrew&lt;/a&gt;. If you&amp;#39;d like to do that, it&amp;#39;s as easy as:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ brew install ssh-copy-id
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Network Configuration&lt;/h2&gt;

&lt;p&gt;I also went ahead and configured the CentOS machines to use static IP addresses. DC/OS runs into issues when the IP addresses change, so DHCP wasn&amp;#39;t really an option in this case. I&amp;#39;ve configured my DHCP server to exclude a range of IP addresses, so I allocated three from that range to these servers. I also setup a DNS server on my Synology NAS and configured them to use that DNS to make things a little easier. &lt;/p&gt;

&lt;h1&gt;Installing DC/OS Requirements&lt;/h1&gt;

&lt;p&gt;With my CentOS installs ready, I needed to start installing the prerequisites for DC/OS. For my setup, I was going with one bootstrap node, one master and one public agent. I&amp;#39;m planning on adding additional agents later with some additional Intel NUCs that I&amp;#39;ve ordered. The installation of the requirements is really pretty straight forward: Python (2.7) and Docker. The DC/OS installation process will actually take care of installing the other dependencies for you.  &lt;/p&gt;

&lt;p&gt;My DC/OS installation is going to use the &lt;a href=&quot;https://dcos.io/docs/1.7/administration/installing/custom/gui/&quot;&gt;GUI&lt;/a&gt; installation method, and you can find the complete list of prereqs in the DC/OS &lt;a href=&quot;https://dcos.io/docs/1.7/administration/installing/custom/system-requirements/&quot;&gt;docs&lt;/a&gt;. I should note that I didn&amp;#39;t actually meet all the requirements in terms of hardware and my DC/OS instance is running OK for my lab needs. &lt;/p&gt;

&lt;h2&gt;Python, Pip, Virtualenv&lt;/h2&gt;

&lt;p&gt;My CentOS 7 installation did come with compatible version of Python, so that pre-req was already satisfied. Next, you&amp;#39;ll need to install pip and virtualenv so that the bootstrap process can install the other dependencies, along with the DC/OS components. My CentOS installation did not come with pip, so here are the steps I followed to get pip running. I decided to use yum to install pip, but you could take an &lt;a href=&quot;https://pip.pypa.io/en/stable/installing/&quot;&gt;alternate approach&lt;/a&gt;.  &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ yum install epel-release

$ yum -y update

$ yum install python-pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This installed a somewhat old version of pip install, so I also went ahead and did a pip upgrade using pip.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;  pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The last Python related dependency was virtualenv, and I went ahead and installed that with pip as well.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;  pip install virtualenv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Docker&lt;/h2&gt;

&lt;p&gt;Next, we need to install Docker on all the nodes. CentOS doesn&amp;#39;t come with Docker installed and the yum repo that it&amp;#39;s configured with comes with a pretty old version of Docker. Luckily, the CentOS &lt;a href=&quot;https://docs.docker.com/engine/installation/linux/centos/&quot;&gt;installation guide&lt;/a&gt; is pretty detailed. The only major deviation for me was I decided to use systemd to manager Docker. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;systemctl enable docker
systemctl start docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default, will also use devicemapper with a thin-pool as the storage driver, which will cause the DC/OS preflight checks to fail and is generally not recommended. Instead, it was easier to use the overlay driver in my case vs configuring LVM2 with devicemapper. Here is my systemd drop-in. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[root@dcos-agent-1 ~]# more /etc/systemd/system/docker.service.d/override.conf 
[Service]
ExecStart=
ExecStart=/usr/bin/docker daemon --storage-driver=overlay -H fd://
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;DC/OS Install&lt;/h1&gt;

&lt;p&gt;With Python and Docker installed, I moved on to the DC/OS install. Following the GUI instructions was mostly straight forward, however it requires a network discovery script for the local/custom installation I was doing. To create a network discovery script, I followed the guidelines from the CLI install&lt;/p&gt;

&lt;p&gt;Next, I made a directory to hold the dcos-install script and used curl to download it.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ mkdir -p /tmp/dcos-install
$ cd /tmp/dcos-install
$ curl -O https://downloads.dcos.io/dcos/EarlyAccess/dcos_generate_config.sh
$bash dcos_generate_config.sh --web
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once that was done, I launched Chrome and pointed at my bootstrap node on port 9000.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/dcos-install-screen.png&quot; alt=&quot;install-gui&quot;&gt;&lt;/p&gt;

&lt;p&gt;Launching this wizard takes you to an installation form. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/deployment-settings.png&quot; alt=&quot;install-gui-2&quot;&gt;&lt;/p&gt;

&lt;p&gt;Complete the form, populating everything with config specific to your environment. As you can see, this will ask you for the ssh key and the IP detection script I mentioned earlier. One annoying thing about the form is the error checking seems to only trigger when modifying a given box, so I needed to go back and change some values to get the verification to retrigger. Once everything is entered, click the Run Pre-Flight button. This will start the Pre Flight checks, which could take some time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/pre-flight.png&quot; alt=&quot;install-gui-3&quot;&gt;&lt;/p&gt;

&lt;p&gt;If all goes well, you should see the following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/pre-flight-complete.png&quot; alt=&quot;install-gui-3&quot;&gt;&lt;/p&gt;

&lt;p&gt;For me, I did not see that screen the first time I tried to run the pre-flight. Fix any errors and try again. For me it was the use of devicemapper with thin-pool storage. Once I changed to the overlay storage driver, I was all set.  &lt;/p&gt;

&lt;p&gt;Finally you can deploy the DC/OS cluster and run the post-flight checks. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/dcos-installed.png&quot; alt=&quot;install-gui-3&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now, you can try and login to your DC/OS install. In my case, it actually took several minutes from when it was complete in the installer GUI to when it was available in the browser. DC/OS will use a number of external authentication sources, I chose to use my Google account.&lt;/p&gt;

&lt;p&gt;Here is what it looks like now, with a couple of tasks running via Marathon.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/dcos/dcos-runnning.png&quot; alt=&quot;install-gui-3&quot;&gt;&lt;/p&gt;

&lt;p&gt;This is a pretty minimal installation, no custom configuration needed in my case. But it was pretty easy to get up and running and I can use it for testing code I&amp;#39;m currently working on and can run several instances of our application. Adding public agents should be pretty straight forward once my new hardware arrives, giving me the ability to run even more workload. &lt;/p&gt;

&lt;h1&gt;DCOS Uninstall&lt;/h1&gt;

&lt;p&gt;If you&amp;#39;re like me, and something goes wrong and you want to start over, you first need to uninstall DC/OS. This is done by:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ bash dcos_generate_config.sh --uninstall
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        <pubDate>Wed, 27 Jul 2016 11:38:37 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/07/27/installing-centos-and-dc-os.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/07/27/installing-centos-and-dc-os.html</guid>
        
        
      </item>
    
      <item>
        <title>Setting Up Local DC/OS Lab - Part One</title>
        <description>&lt;p&gt;In my new role, I&amp;#39;m working pretty extensively with Marathon and Mesos. Prior to moving to my home office, I setup a Marathon and Mesos cluster using my &lt;a href=&quot;/3d-printing,nuc,lab/2014/08/05/3d-print-all-the-things.html&quot;&gt;Link text&lt;/a&gt; lab. That lab was still in the office taking up (limited) space on someone&amp;#39;s desk so I&amp;#39;ve still been using it, but the network connectivity between my hosue and the office meant that I had noticable delay when transfering Docker images to the docker registry running on the lab. On Friday, I decided to bring it home and set it up in my basement. &lt;/p&gt;

&lt;p&gt;I could keep the cluster running as is, but I&amp;#39;ve decided to reinstall it using DC/OS instead of simply installing Marathon and Mesos again. I&amp;#39;ve also decided to recreate the storage volume on the NAS, as it still contained things from my previous role that I no longer needed. This will be a totally clean rebuild of the lab then! I&amp;#39;ll need to setup the NAS again, along with the hosts, followed by the DC/OS setup. I&amp;#39;ll also need to run a docker registry to support what I am doing. I&amp;#39;ll use the NAS to provide storage for the docker registry and mostly use the host storage for the Mesos agents, although I&amp;#39;ll also do some research for persistent volumes from Mesos and will use it. It&amp;#39;s got around 2 TB of storage if I set it up with RAID1. &lt;/p&gt;

&lt;p&gt;My original plan was to run &lt;a href=&quot;https://coreos.com/&quot;&gt;CoreOS&lt;/a&gt; on the hosts, but I don&amp;#39;t think that really fits with my needs right now (i.e. I don&amp;#39;t need etcd or other features of CoreOS right now), so  I&amp;#39;ll revisit that later. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/pxeboot.png&quot; alt=&quot;pxeboot&quot;&gt;&lt;/p&gt;

&lt;p&gt;I was able to setup a PXE boot server using my NAS, since Synology supports that pretty well. In the short term, I thought I would  use &lt;a href=&quot;http://www.ubuntu.com/&quot;&gt;Ubuntu&lt;/a&gt; since I know that I can install that on the NUCs without much troubleshooting. However, Ubuntu is currently not supported by the DC/OS installation scripts, so I&amp;#39;ll use &lt;a href=&quot;https://www.centos.org/&quot;&gt;CentOS&lt;/a&gt;. This will be a mirror of what we&amp;#39;re using in production at the moment. I previously had to make some BIOS changes to get Ubuntu running on the NUCs, so I&amp;#39;m guessing I&amp;#39;ll need to do something similar for CentOS.    &lt;/p&gt;

&lt;p&gt;I currently have the hardware setup in the basement, using some old entertainment centers to hold everything. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/basement_lab.png&quot; alt=&quot;lab&quot;&gt;&lt;/p&gt;

&lt;p&gt;In the next blog, I&amp;#39;ll cover getting CentOS running on the hosts. After that, I&amp;#39;ll follow up with getting DC/OS running. I currently have the bare minimum for running DC/OS, so I think I&amp;#39;ll probably buy another NUC or two over the coming weeks and add them as Mesos agents. &lt;/p&gt;
</description>
        <pubDate>Sat, 23 Jul 2016 20:22:26 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/07/23/setting-up-local-dc-os-lab.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/07/23/setting-up-local-dc-os-lab.html</guid>
        
        
      </item>
    
      <item>
        <title>Painful Lesson</title>
        <description>&lt;p&gt;We are using &lt;a href=&quot;http://mesos.apache.org/&quot;&gt;Mesos&lt;/a&gt; and &lt;a href=&quot;https://mesosphere.github.io/marathon/&quot;&gt;Marathon&lt;/a&gt; to run our Dockerized system. In the matter of two days, I learned a painful lesson. Namely, the following is a terrible, terrible practice:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;  &lt;span class=&quot;s2&quot;&gt;&amp;quot;container&amp;quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;quot;docker&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;image&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;repo/image-name:latest&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;forcePullImage&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;network&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;BRIDGE&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;portMappings&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;quot;containerPort&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;quot;hostPort&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using forcePullImage : true and the latest tag on the image goes really badly when you implement CD and push images with breaking changes to your repository. In our current deployment scenario, we run a cluster of three containers. The implication with forcePullImage : true is that anytime the container is restarted, it will pull the latest of whatever image is specified and start with that. That is GREAT for testing out new changes when you manually initiate a restart across the cluster. That is TERRIBLE when one of the containers dies and restarts with the new image, leading to an inconsistent cluster. This of course happened overnight in our staging environment!&lt;/p&gt;

&lt;p&gt;We&amp;#39;re now pushing images that make it through our image promotion process with specific tags and we are not using the forcePullImage setting. This poses an issue: what if we DO want to have it pull the image? Really, the solution here is another tag. If there is a problem with the image, it should be replaced with a new verison. &lt;/p&gt;

&lt;p&gt;If you DO need to force an image pull, you can change the Marathon configuration to specify that, causing a restart (after the pull). You&amp;#39;d likely want to then change it again to change it back, but this would also result in a restart. Another option might be to run a non-container task and execute &amp;#39;docker pull&amp;#39; on each of the Agents (slaves in old Mesos terminology). That might look something like:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;{
  &amp;quot;id&amp;quot;: &amp;quot;test-pull&amp;quot;,
  &amp;quot;instances&amp;quot;: 3,
  &amp;quot;mem&amp;quot;: 128.0,
  &amp;quot;cpus&amp;quot;: 1,
  &amp;quot;cmd&amp;quot;: &amp;quot;sudo docker pull %%IMAGE_NAME%%&amp;quot;,
  &amp;quot;constraints&amp;quot;: [
    [
      &amp;quot;hostname&amp;quot;,
      &amp;quot;UNIQUE&amp;quot;
    ]
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, you&amp;#39;d want to replace the instances attribute with the number of agents in your cluster. The hostname : UNIQUE constraint should force this to run on each of the agents.&lt;/p&gt;

&lt;p&gt;This probably isn&amp;#39;t the greatest use of Marathon, as it will run this task over and over again. Once it is run, you probably want to delete the app from Marathon to prevent this. A better alternative might be to use &lt;a href=&quot;https://mesos.github.io/chronos/&quot;&gt;Chronos&lt;/a&gt; or &lt;a href=&quot;https://github.com/klarna/eremetic&quot;&gt;Eremetic&lt;/a&gt; &lt;/p&gt;
</description>
        <pubDate>Wed, 20 Jul 2016 10:42:45 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/07/20/hard-lesson.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/07/20/hard-lesson.html</guid>
        
        
      </item>
    
      <item>
        <title>2FA</title>
        <description>&lt;p&gt;I&amp;#39;m working on SaaS things lately and I decided to check out the SaaS based 2FA providers. I did a Google search for &amp;quot;SaaS 2FA&amp;quot; and the first response I got was &lt;a href=&quot;https://duo.com/&quot;&gt;duo security&lt;/a&gt;, which happens to be based in my home state of Michigan!&lt;/p&gt;

&lt;p&gt;Taking a look a their website, they have quite a few &lt;a href=&quot;https://duo.com/solutions/features/supported-applications&quot;&gt;integrations&lt;/a&gt;. One of them is PAM support, so I thought I&amp;#39;d check that out. I fired up a CentOS VM and followed their &lt;a href=&quot;https://duo.com/docs/duounix&quot;&gt;docs&lt;/a&gt; and within about 5 minutes I had two-factor auth enabled for my linux VM.&lt;/p&gt;

&lt;p&gt;First, I needed to grab some dependencies since I was running CentOS minimal, mainly a C compiler and both the pam-devel and openssl-devl libraries.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-console&quot; data-lang=&quot;console&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; yum group install &lt;span class=&quot;s2&quot;&gt;&amp;quot;Development Tools&amp;quot;&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; yum install pam-devel
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; yum install openssl-devel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One that was completed, I grabbed the source and built the duo unix package with pam support.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-console&quot; data-lang=&quot;console&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; wget https://dl.duosecurity.com/duo_unix-latest.tar.gz
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; tar zxf duo_unix-latest.tar.gz
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;duo_unix-1.9.18
&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; ./configure --with-pam --prefix&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; make &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, I modified the /etc/pam.d/sshd config file:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/pam-config.png&quot; alt=&quot;conf&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;auth       required pam_env.so
auth       sufficient pam_duo.so
auth       required pam_deny.so
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and changed the value of ChallengeResponseAuthentication in my /etc/ssh/sshd_config file to yes. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;ChallengeResponseAuthentication yes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, I restarted ssdh&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-console&quot; data-lang=&quot;console&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$&lt;/span&gt; systemctl restart bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once I tried to login via SSH, I was promted to enroll at the URL given. I loaded that up in the browser and entered my phone number. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/duo-enroll.png&quot; alt=&quot;enroll&quot;&gt;&lt;/p&gt;

&lt;p&gt;I opened a new SSH session and got the 2FA promptes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/duo-login.png&quot; alt=&quot;login&quot;&gt;&lt;/p&gt;

&lt;p&gt;I selected the push option and got a notification on my phone almost immediately.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/duo-app-push.png&quot; alt=&quot;push notification&quot;&gt;&lt;/p&gt;

&lt;p&gt;Pretty cool.&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Jul 2016 10:47:57 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/07/01/2fa.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/07/01/2fa.html</guid>
        
        
      </item>
    
      <item>
        <title>Working Remotely</title>
        <description>&lt;p&gt;In early January, the majority of the R&amp;amp;D team in my office was laid off in an effort to streamline products and development sites. This included my team and our product &lt;a href=&quot;https://www.vmware.com/cloud-services/management/&quot;&gt;vRealize Air Compliance&lt;/a&gt;. Luckily, I found another position within the company and would be able to stay in Colorado. I&amp;#39;m not working remotely with team members in Palo Alto (California) and Herzliya (Israel). It&amp;#39;s been a big change, to say the least. I kept my desk in the office, but I found myself working from home more and more. I finally decided to give up my desk and covert to a home office.&lt;/p&gt;

&lt;p&gt;The transition has been pretty seemless since I&amp;#39;ve been working from home so much. I was able to bring a couple of monitors home with me and setup my standing desk so I essentially have the same setup as I had at the office!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/standing-desk.jpeg&quot; alt=&quot;Desk&quot;&gt; &lt;/p&gt;

&lt;p&gt;The desk is made from my existing &lt;a href=&quot;http://www.ikea.com/us/en/catalog/products/60193736/&quot;&gt;IKEA Lack Side Tables&lt;/a&gt;, along with a new &lt;a href=&quot;http://www.ikea.com/us/en/catalog/products/S29932181/&quot;&gt;LINNMON / ADILS&lt;/a&gt;. I had to make a few adjustments, but it ended up being essentially the perfect height. My new &lt;a href=&quot;http://www.wasdkeyboards.com/&quot;&gt;WASD Keyboard&lt;/a&gt; is a little bigger than the Apple keyboard I had been using, so most of the adjustment had to be done to the keyboard ledge. &lt;/p&gt;

&lt;p&gt;The room I decided to use as a home office is our &amp;quot;technology&amp;quot; room and already had a PC for my son to use, along with my wife&amp;#39;s knitting and my turntable. Oddly enough, it&amp;#39;s the only room in the house that wasn&amp;#39;t wired with Cat6 when the house was built. My next project is either running ethernet to the room or upgrading the wireless in the house.   &lt;/p&gt;
</description>
        <pubDate>Sun, 05 Jun 2016 17:32:48 -0600</pubDate>
        <link>http://jrrickard.github.io/2016/06/05/working-remotely.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2016/06/05/working-remotely.html</guid>
        
        
      </item>
    
      <item>
        <title>AWS Lambda and Alexa Skills Kit</title>
        <description>&lt;p&gt;A few months ago, I bought an Amazon Echo because I have a ton of music in the Amazon ecosystem. When they announced the &lt;a href=&quot;https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit&quot;&gt;Alexa Skills Kit&lt;/a&gt;, I was excited to try it out. I had already done a few things with &lt;a href=&quot;https://aws.amazon.com/lambda/&quot;&gt;AWS Lambda&lt;/a&gt;, so I was already familiar with writing a lambda function. I decided a quick way to try it out would be to implement something with ASK that I had done previously. I recently wrote a bot for Slack using go and one of it&amp;#39;s first functions was to do things with the Rally Web Services API. That seemed like a fun thing to do with the Echo as well. I already ask the Echo for the weather and a couple other things in the morning...what If I could ask it what bugs I have to fix? I created a github repo to store everything I describe below.
I started out by grabbing the &lt;a href=&quot;https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/using-the-alexa-skills-kit-samples&quot;&gt;reference skills&lt;/a&gt;. I already had a develoepr account, so once I had the reference skills I was able to register them on the develoepr portal and try them out. Developing a skill turns out to be &lt;strong&gt;REALLY&lt;/strong&gt; simple. You basically come up with an interaction model, write some JavaScript, upload it to AWS, do a little configuration and it&amp;#39;s ready to go.&lt;/p&gt;

&lt;p&gt;Using the references as a starting point, I came up with an interaction model. The first thing I would implement with the Rally API was fetching my defects. The recommended interaction design is to ask your service for something. You might say, &amp;quot;Alexa, ask &lt;Invocation Name&gt; for &lt;intent trigger&gt;. I originally started out with &amp;quot;my current defects&amp;quot; for the intent trigger, but it was more natural for me to say bugs so I went with that. Getting bugs from the Echo would be:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;Alexa, ask Rally for my current bugs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Rally would become the Invocation Name. We&amp;#39;ll look at configuring that in a minute.&lt;/p&gt;

&lt;p&gt;Now it was time to implement my lambda function. I had two choices here, I could implement a client for the Rally WS API myself, or use the &lt;a href=&quot;https://github.com/RallyTools/rally-node&quot;&gt;unsupported Node.js library&lt;/a&gt; that Rally developed. I went with the library to avoid reinventing the wheel. It&amp;#39;s easy to use Node libraries with Lambda, you just need to delivery the library with the Lambda function. The easiest way to do this is to run the npm install and specify a prefix so that it installs in the same directory as your lambda code. Then you can simply zip up the entire directory and upload that to the AWS console. In my case, I had created a directory called &amp;quot;rally-tasks-for-echo&amp;quot; and a &amp;quot;src&amp;quot; directory under that to hold all the JavaScript. Installing the node library was just:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;fermat:rally-tasks-for-echo jeremy$ npm install --prefix=src rally
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, when I looked in the src directory, I had a node_modules subdirectory with the Rally library and the associated dependencies.&lt;/p&gt;

&lt;p&gt;Next, I needed a way to configure the Lambda. I decided to create a JSON document with my read-only Rally key, my project ID and my username and stoer that in S3. This ended up being a really easy way to store the configuration. Here is an example:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;{
        &amp;quot;key&amp;quot; : &amp;quot;INSERT_RALLY_KEY&amp;quot;,
        &amp;quot;projectID&amp;quot; : &amp;quot;INSERT_RALLY_PROJECT_ID&amp;quot;,
        &amp;quot;user&amp;quot; : &amp;quot;INSERT_USERNAME&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The actual Lambda function is pretty simple, so I won&amp;#39;t go into it much here. Simply zip up the directory with the source code and keep the file handy. Once it was written I had to configure both the Lambda and the Skill. Once all the configuration is done, I need to come back and update the source code with the appId of the skill. The Lambda should be first.&lt;/p&gt;

&lt;p&gt;First, login to the AWS Console. Then Click on the Lambda link. It&amp;#39;s also important to make sure you are using the us-east region, as the other regions are not supported for ASK yet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/lambda-option.png&quot; alt=&quot;aws console&quot;&gt;&lt;/p&gt;

&lt;p&gt;Then create a new Lambda function. I skipped the blueprint and just went with a blank configuration. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/create-lambda.png&quot; alt=&quot;new function&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now, name the function and pick Node.js as the Runtime. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/configure-function.png&quot; alt=&quot;configure-function-step-one&quot;&gt;&lt;/p&gt;

&lt;p&gt;Change the code entry type to &amp;quot;Upload a ZIP File&amp;quot; and click the Upload button and locate your file. &lt;/p&gt;

&lt;p&gt;Once uploaded, keep the Handler as index.handler, that matches up against the handler function defined in index.js. For role, I selected the basic Lambda exeuction policy and that seemed sufficient.&lt;/p&gt;

&lt;p&gt;The major thing I had to change was the default timeout period for the function. The Rally API can take a few seconds to return, so I upped the timeout to 20 seconds. Probably more than needed but I wanted to be safe. Something to consider is that based on Lambda pricing, increasing the timeout could have a cost impact. I don&amp;#39;t think that I&amp;#39;ll exceed the free invocation limits so I wasn&amp;#39;t too worried about it here.&lt;/p&gt;

&lt;p&gt;The final bit of configuration for the Lambda function is to add an event source to it. Edit the function by clicking on it&amp;#39;s name, then click the &amp;quot;Event sources&amp;quot; tab and click &amp;quot;Add event source&amp;quot; once that loads. Select Alexa Skills Kit from the Event source type drop down, then click submit.&lt;/p&gt;

&lt;p&gt;Now the Lambda is configured. Now go to the Alexa Developer Portal (https://developer.amazon.com/edw/home.html#/) and click Alexa, then Get Started under Alexa Skills Kit. Pick a name for the skill and an invocation name. As I mentioned above, I picked Rally for my invocation name. I also used that as the name. I also entered the ARN from my Lambda function here. Copy the Application Id on this page for use later. We&amp;#39;ll need to add that to the skill lambda code.  &lt;/p&gt;

&lt;p&gt;Next, I copy and pasted the contents of the speechAssets files into the text fields on the next screen. &lt;/p&gt;

&lt;p&gt;Now that the skill is set up, I should have an application id associated with it.  Take the application id and paste it into the source code from the git repo above, replacing the template value that is there. Upload the code again and you should be able to test it with your Echo.&lt;/p&gt;

&lt;p&gt;Here is mine: &lt;/p&gt;

&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/KfkRT0aDw5o&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
</description>
        <pubDate>Mon, 14 Sep 2015 07:49:23 -0600</pubDate>
        <link>http://jrrickard.github.io/2015/09/14/aws-lambda-and-alexa-skills-kit.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2015/09/14/aws-lambda-and-alexa-skills-kit.html</guid>
        
        
      </item>
    
      <item>
        <title>Headless Selenium Test With Docker Jenkins Slave</title>
        <description>&lt;p&gt;In an earlier blog post, I wrote about building Docker based jenkins slaves. I used that to automate deployment of our system and clients from Jenkins. With that working, I wanted to apply the same to running some of our UI automation. We&amp;#39;re currently using a series of Windows virtual machines as remote slaves and Sikuli based tests. The downside to these tests is that they are based on image capture and actually driving a browser, so we can only one run at a time per slave and they can fail if resolution of the VM is changed or something is launched that is on top of the browser. One fix for this would be to use something like selenium instead. I implemented a subset of the tests using selenium and I&amp;#39;ve been able to run these on my laptop using the Firefox browser just fine. &lt;/p&gt;

&lt;p&gt;With the tests running with selenium, I wondered if we could run them headlessly via the Docker slave mechanism. To do that, I needed a new slave image. Starting with the evarga/jenkins-slave base image, I installed maven, git, firefox and xfvb. I also generated an ssh key, registered it with our git instance and then added it to the container.   &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;FROM evarga/jenkins-slave:latest

ENV DEBIAN_FRONTEND noninteractive
ENV DEBCONF_NONINTERACTIVE_SEEN true

#===================
# Timezone settings
# Possible alternative: https://github.com/docker/docker/issues/3359#issuecomment-32150214
#===================
ENV TZ &amp;quot;US/Mountain&amp;quot;
RUN echo &amp;quot;US/Mountain&amp;quot; | sudo tee /etc/timezone \
  &amp;amp;&amp;amp; dpkg-reconfigure --frontend noninteractive tzdata

#==============
# Xvfb, firefox, maven, git
#==============
RUN apt-get update -qqy \
  &amp;amp;&amp;amp; apt-get -qqy install \
    xvfb firefox maven git \
  &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

#============================
# Some configuration options, same size as MacBook display
#============================
ENV SCREEN_WIDTH 1680
ENV SCREEN_HEIGHT 1050
ENV SCREEN_DEPTH 24
ENV DISPLAY :99.0

COPY id_rsa /home/jenkins/.ssh/
COPY id_rsa.pub /home/jenkins/.ssh/
RUN chown jenkins /home/jenkins/.ssh/
RUN chmod 600 /home/jenkins/.ssh/id_rsa
USER jenkins
RUN ssh-keyscan qeconfig.wp.fsi &amp;gt;&amp;gt; /home/jenkins/.ssh/known_hosts
RUN chmod 600 /home/jenkins/.ssh/id_rsa.pub
RUN chmod 600 /home/jenkins/.ssh/known_hosts
USER root
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When all is said and done, that&amp;#39;s a fairly large image. Again, starting from scratch might lead to a smaller image.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;jeremy@euclid [ ~/ui-test ]$ sudo docker images
REPOSITORY             TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
ui-test.slave          latest              f06dd6a0ba85        35 seconds ago      832.2 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the image created, I followed the same process of adding a new template to the Docker cloud defined in Jenkins. Then created a new job. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://jrrickard.github.io/images/docker-label.png&quot; alt=&quot;Job config&quot;&gt;
&lt;img src=&quot;http://jrrickard.github.io/images/shell-commands.png&quot; alt=&quot;Shell commands&quot;&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Sep 2015 08:15:57 -0600</pubDate>
        <link>http://jrrickard.github.io/2015/09/07/headless-selenium-tests-with-docker-jenkins-slave.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2015/09/07/headless-selenium-tests-with-docker-jenkins-slave.html</guid>
        
        
      </item>
    
      <item>
        <title>Using Octopress 3.0 with Github Pages</title>
        <description>&lt;p&gt;This blog has been dormant for a while. I was using a fairly old version of octopress and at some point ended up corrupting my repo. Then I got way to busy with the &lt;a href=&quot;http://vrealizeair.vmware.com/compliance&quot;&gt;vRealize Air Compliance&lt;/a&gt; to fix it. Now that we&amp;#39;ve released, I thought it was time to get this thing running again. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/octopress/octopress&quot;&gt;Octopress 3.0&lt;/a&gt; is available on github, so I thought I&amp;#39;d try that out. Rather than try and upgrade my existing instance, I went ahead and killed my github pages repo and start from scratch there. I also had a new Macbook, so I might as well try and set everything up from scratch.&lt;/p&gt;

&lt;h1&gt;Step one, create a new repo&lt;/h1&gt;

&lt;p&gt;To use github pages, you create a repo of the form username.github.io. In my case, that was jrrickard.github.io. Next, I followed the &lt;a href=&quot;https://help.github.com/articles/using-jekyll-with-pages/&quot;&gt;Usng Jekyll with Pages&lt;/a&gt; page to get started up to the &amp;quot;Running Jekyll&amp;quot; section of the page.&lt;/p&gt;

&lt;h1&gt;Step two, get Octopress&lt;/h1&gt;

&lt;p&gt;I modified the Gemfile created above and added:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gem &amp;#39;octopress&amp;#39;, &amp;#39;~&amp;gt; 3.0.0&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once I did that, I did a bundle update &amp;amp;&amp;amp; bundle install to make sure I had the new gem. Now I had the octopress cli. This has been &lt;em&gt;much&lt;/em&gt; easier to use than the previous version of octopress. Now I had everything installed, I needed to init the new blog. You can do that with Jekyll, or you can use the octopress cli and it will also copy over all the octopress scaffolding. I went with the octopress:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# octopress new jrrickard.github.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That created a new directory called jrrickard.github.io with the scaffolding. Next I changed into that diretory and did a jekyll build&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# jekyll build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This went through the directory and created the _site directory with all of the content of the blog. Now I could serve it up:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This started up a server listening on port 4000 so I could view the content. &lt;/p&gt;

&lt;p&gt;The last step of getting it setup was doing the deploy init. Again, very easy with the octopress cli:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# octopress deploy init git git@github.com:jrrickard/jrrickard.github.io.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once that was done, I added the _deploy.yml file to my .gitignore. Once I was done, the .gitignore looked like:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;_site
.sass-cache
_deploy.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, running deploy with the octopress cli pushed to my git repo:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# octopress deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, the new blog was available at my Github pages url. Now I just needed content!&lt;/p&gt;

&lt;h1&gt;Step three, move all the old content.&lt;/h1&gt;

&lt;p&gt;This part was simple. I still had all the markdown and image files from my original blog, so I moved them over to this new directory structure and put the existing markdown files in the _posts directory. I created an images folder and copied all the images over into that one. Once I ran the jekyll build to regenerate everything, I noticed I didn&amp;#39;t have the old octopress img plugin installed. I went ahead and replaced those with normal markdown and the Jekyll site.url template (make sure you update your _config.yaml to have that correctly defined). &lt;/p&gt;

&lt;h1&gt;Step four, new posts!&lt;/h1&gt;

&lt;p&gt;While my blog was messed up, I had done a few gist based blogs. I wanted to move them over here, so I used the cli to create some new posts:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# octopress new blog &amp;quot;Running lattice.cf on VMware AppCatalyst&amp;quot;
# octopress new blog &amp;quot;Creating a Docker Jenkins Slave Running on a VMware Photon VM&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This created two new files in the _posts directory with that title and today&amp;#39;s date. It sticks the correct header/front matter in a blank file. So I modified the filename to have the correct dates and updated the date meta data in the file. Then I simply copied the markdown from the Gists and placed them in the appropriate file. The only major change I had to do was to change the Github markdown preformat token (three `) to normal markdown (4 ~). Once I had done that, getting everything deployed again was simply:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# jekyll build
# octopress deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then voila, the blog is updated. Simple.&lt;/p&gt;
</description>
        <pubDate>Fri, 04 Sep 2015 20:14:30 -0600</pubDate>
        <link>http://jrrickard.github.io/2015/09/04/installing-octopress-3-0.html</link>
        <guid isPermaLink="true">http://jrrickard.github.io/2015/09/04/installing-octopress-3-0.html</guid>
        
        
      </item>
    
  </channel>
</rss>
